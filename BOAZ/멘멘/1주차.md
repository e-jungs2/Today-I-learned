# 1장. 머신 러닝과 딥러닝

## 1.1 인공지능, 머신 러닝과 딥러닝

**인공지능 > 머신 러닝 > 딥러닝**
![alt text](../img/멘멘/1주차/1.png)

- 머신 러닝 : 주어진 데이터를 인간이 전처리. 범용적인 목적을 위해 제작된 것으로 **데이터의 특징을 스스로 추출하지 못함**. → 전처리 필요. 각 데이터 특성을 컴퓨터에 인식시키고 학습시켜 문제 해결.
- 딥러닝 : **인간이 하던 작업 생략**. 대량의 데이터를 신경망에 적용하면 컴퓨터가 스스로 분석한 후 답을 찾음.

![alt text](../img/멘멘/1주차/2.png)

![alt text](<스크린샷 2025-07-15 173302.png>)

## 1.2 머신 러닝이란

### 1.2.1 머신 러닝 학습 과정
![alt text](../img/멘멘/1주차/3.png)

- 크게 학습 단계와 예측 단계로 구분됨.
- 데이터 : 머신 러닝이 학습 모델을 만드는 데 사용. 특성을 잘 반영하기 위해서는 실제 데이터의 특징이 잘 반영되고 편향되지 않는 훈련 데이터를 확보해야 함. ‘훈련 데이터셋’과 ‘검증 데이터셋’으로 분리해서 사용하기도 함.(8:2로 split하는 것이 일반적)
- 모델 : 머신 러닝의 학습 단계에서 얻은 최종 결과물. 가설이라고도 함. **“입력 데이터의 패턴은 A와 같다.”라는 가정을 머신 러닝에서는 모델이라고 함.**

> 모델 = 우리가 데이터 관계를 설명하기 위해 세운 함수이므로, “이런 구조로 설명될 것이다.”라는 가설을 세운 후, 시험해 보고 검증하는 과정의 산물이기 때문.
> 
1. 모델(또는 가설) 선택
2. 모델 학습 및 평가
3. 평가를 바탕으로 모델 업데이트
- 훈련 데이터셋에 대한 정확도는 높은데 검증 데이터셋에 대한 정확도가 낮음 → 훈련 데이터셋에 과적합. → 정규화 or 에포크를 줄이는 방식으로 방지.

### 1.2.2 머신 러닝 학습 알고리즘

- **지도 학습 :** 정답이 무엇인지 컴퓨터에 알려주고 학습시키는 방법.
- **비지도 학습** : 정답을 알려주지 않고 특징이 비슷한 데이터를 클러스터링하여 예측하는 학습 방법.
![alt text](../img/멘멘/1주차/5.png)

- **강화 학습 :** 분류할 수 있는 데이터가 있는 것도 아니고 데이터가 있다고 해도 정답이 없기 때문. 강화 학습은 자신의 행동에 대한 보상을 받으며 학습을 진행함. 강화 학습은 이러한 보상이 커지는 행동은 자주 하도록 하고, 줄어드는 행동은 덜 하도록 하여 학습을 진행함.

### 1.3.1 딥러닝 학습 과정

1. 데이터 준비 : 파이토치, 케라스 / 캐글
2. 모델(모형) 정의 : 은닉층 개수가 많을수록 성능이 좋아지지만, 과적합이 발생할 확률이 높음. 
3. 모델(모형) 컴파일 : 활성화 함수, 손실 함수, 옵티마이저를 선택함.

훈련 데이터셋 형태가 연속형 ⇒ 평균 제곱 오차(MSE)

이진 분류 ⇒ 크로스 엔트로피(두 확률 분포 간의 차이를 정량화하는 지표로, 머신러닝에서는 주로 **실제 분포**와 **모델이 예측한 분포**의 차이를 평가하는 손실 함수)

1. 모델(모형) 훈련 : 한 번에 처리할 데이터양 지정. ← 에포크 선택. 파라미터와 하이퍼마라미터에 대한 최적의 값을 찾을 수 있어야 함.
2. 모델(모형) 예측 : 검증 데이터셋을 생성한 모델(모형)에 적용하여 실제로 예측을 진행해 보는 단계. 예측력이 낮다면 파라미터를 튜닝, 신경망 자체를 재설계.
- 역전파 : 가중치 값을 업데이트 하기 위해.

![alt text](../img/멘멘/1주차/6.png)

### 1.3.2 딥러닝 학습 알고리즘

**<지도 학습>**
- 합성곱 신경망(CNN) : 컴퓨터 비전에 많이 사용됨. 목적에 따라 이미지 분류, 이미지 인식, 이미지 분할로 분류됨.
- 순환 신경망(RNN) : 시계열 데이터를 분류할 때 사용됨. 역전파 과정에서 기울기 소멸 문제가 발생하는 단점이 있음.
- LSTM : RNN이 가지고 있는 문제점을 개선하고자 게이트 세 개를 추가. 망각 게이트, 입력 게이트, 출력 게이트 도입을 통해 기울기 소멸 문제 해결.

**<비지도 학습>**
- 워드 임베딩 : 단어를 벡터로 표현. 워드투벡터, 글로브 많이 사용.
- 군집 : 아무런 정보가 없는 상태에서 데이터를 분류하는 방법. 머신 러닝의 군집과 다르지 않음. 머신 러닝에서 군집화를 처리할 때 딥러닝과 함께 사용하면 모델 성능을 높일 수 있기 때문에 딥러닝과 함께 사용하면 좋음.

**<전이 학습>**\
사전에 학습이 완료된 모델을 가지고 우리가 원하는 학습에 미세 조정 기법을 이용하여 학습시키는 방법.

**<사전 학습 모델>**\
풀고자 하는 문제와 비슷하면서 많은 데이터로 이미 학습이 되어 있는 모델. VGG, 인셉션, MoblieNet 같은 사전 학습 모델을 사용하면 효율적 학습 가능.

![alt text](../img/멘멘/1주차/7.png)
---

# 2장. 실습 환경 설정과 파이토치 기초

## 2.1 파이토치 개요

- 넘파이를 대체하면서 GPU를 이용한 연산이 필요한 경우
- 최대한의 유연성과 속도를 제공하는 딥러닝 연구 플랫폼이 필요한 경우

> 간결하고 빠른 구현성

### 2.1.1 파이토치 특징 및 장점

**GPU에서 텐서 조작 밑 동적 신경망 구축이 가능한 프레임워크**

- GPU : 연산 속도를 빠르게 하는 역할.
- 텐서 : 파이토치의 데이터 형태. 단일 데이터 형식으로 된 자료들의 다차원 행렬. GPU로 연산을 수행하게 할 수 있음.

```python
import torch
torch.tensor([[1., -1.], [1., -1.]])
```
![alt text](../img/멘멘/1주차/8.png)

- 동적 신경망 : 훈련을 반복할 때마다 네트워크 변경이 가능한 신경망. 학습 중 은닉층을 추가하거나 제거하는 등 모델의 네트워크 조작 가능. 연산 그래프를 정의하는 것과 동시에 값도 초기화되는 ‘Define by Run’방식을 사용함. 연산 그래프와 연산을 분리해서 생각할 필요가 없음 → 코드를 이해하기 쉬움.

![alt text](../img/멘멘/1주차/9.png)

### 2.1.2 파이토치의 아키텍처
![
!\[image.png\](attachment:da53faee-8df6-4e91-a52f-9aa70b38de9c:image.png)](../img/멘멘/1주차/10.png)

- **파이토치 API**

사용자 인터페이스 제공. 실제 계산을 수행하진 않음. C++로 작성된 파이토치 엔진으로 그 작업을 전달하는 역할을 함.

```
torch : GPU를 지원하는 텐서 패키지
torch. autograd : 자동 미분 패키지
torch.nn : 신경망 구축 및 훈련 패키지
torch.multiprocessing : 파이썬 멀티프로세싱 패키지
torch.utils : DataLoader 및 기타 유틸리티를 제공하는 패키지
```

- **파이토치 엔진**

파이토치 엔진 라이브러리는 C++로 감싼 다음 Python API 형태로 제공되기 때문에 사용자들이 손쉽게 모델을 구축하고 텐서를 사용할 수 있음.

![!\[alt text\](<스크린샷 2025-07-17 021157.png>)
](../img/멘멘/1주차/11.png)

- **연산 처리**

가장 아래 계층에 속하는 C 또는 CUDA 패키지는 상위의 API에서 할당된 거의 모든 계산을 수행함. 효율적인 데이터 구조, 다차원 텐서에 대한 연산을 처리함.

## 2.2 파이토치 기초 문법

### 2.2.3 모델 정의

- 계층 : 모듈 또는 모듈을 구성하는 한 개의 계층으로 합성곱층, 선형 계층 등이 있음.
- 모듈 : 한 개 이상의 계층이 모여서 구성된 것. 모듈이 모여 새로운 모듈을 만들 수 있음.
- 모델 : 최종적으로 원하는 네트워크. 한 개의 모듈이 모델이 될 수도 있음.

![alt text](../img/멘멘/1주차/12.png)

### 2.2.4 모델의 파라미터 정의

- 손실 함수 : 학습하는 동안 출력과 정답 사이의 오차를 측정함.

BCELoss, CrossEntropyLoss, MSELoss

- 옵티마이저 : 데이터와 손실 함수를 바탕으로 모델의 업데이트 방법을 결정.

step() 메서드를 통해 전달받은 파라미터를 업데이트함.

모델의 파라미터별로 다른 기준을 적용시킬 수 있음.

- 학습률 스케줄러 : 미리 지정한 횟수의 에포크를 지날 때마다 학습률을 감소시켜 줌. 학습 초기에는 빠른 학습을 진행하다가 전역 최소점 근처에 다다르면 학습률을 줄여서 최적점을 찾아갈 수 있도록 해 줌.

![!\[image.png\](attachment:21fc49b7-675a-4d58-9391-9ee7ef728992:image.png)](../img/멘멘/1주차/13.png)

- 지표 : 훈련과 테스트 단계를 모니터링함.

### 2.2.5 모델 훈련

y=wx+b라는 함수에서 w와 b의 적절한 값을 찾는 것과 같음. w와 b에 임의의 값을 적용하여 시작하며 오차가 줄어들어 전역 최소점에 이를 때까지 파라미터(w, b)를 계속 수정함.

1. otimizer.zero.grad() 메서드를 이용하여 기울기를 초기화함.
2. loss.backward() 메서드를 이용하여 기울기를 자동 계산함.

![alt text](../img/멘멘/1주차/14.png)

### 2.2.6 모델 평가

1. 함수
2. 모듈
3. 사이킷런을 제공하는 혼동 행렬

### 2.2.7 훈련 과정 모니터링

텐서보드를 이용하면 학습에 사용되는 각종 파라미터 값이 어떻게 변화하는지 손쉽게 시각화하여 살펴볼 수 있으며 성능을 추적하거나 평가하는 용도로도 사용됨.

1. 텐서보드 설정
2. 텐서보드 기록
3. 텐서보드를 사용하여 모델 구조를 살펴봄.

## 2.3 실습 환경 설정

![!\[image.png\](attachment:3226ed05-696e-48b9-ab80-a050edf786e7:image.png)](../img/멘멘/1주차/15.png)

가상환경 활성화!

## 2.4 파이토치 코드 맛보기

https://github.com/e-jungs2/Today-I-learned/blob/main/BOAZ/%EB%A9%98%EB%A9%98/1%EC%A3%BC%EC%B0%A8.ipynb

<성능 평가 지표>

- True Postive : 모델이 ‘1’이라고 예측했는데 실제 값도 ‘1’인 경우
- True Negative : 모델이 ‘0’이라고 예측했는데 실제 값도 ‘0’인 경우
- False Postive : 모델이 ‘1’이라고 예측했는데 실제 값은 ‘0’인 경우, 제 1종 오류
- False Negative : 모델이 ‘0’이라고 예측했는데 실제 값은 ‘1’인 경우, 제 2종 오류

**정확도** : 전체 예측 건수에서 정답을 맞힌 건수의 비율

$$
\mathrm{Accuracy}
= \frac{\text{True Positive} + \text{True Negative}}
       {\text{True Positive} + \text{True Negative} + \text{False Positive} + \text{False Negative}}

$$

**재현율** : 실제로 정답이 1이라고 할 때 모델도 1로 예측한 비율. 처음부터 데이터가 1일 확률이 적을 때 사용.

$$
\mathrm{재현율}= \frac{\text{True Positive}}       {\text{True Positive} + \text{False Positive}}
$$

**정밀도** : 모델이 1이라고 예측한 것 중에서 실제로 정답이 1인 비율.

$$
\mathrm{재현율}= \frac{\text{True Positive}}       {\text{True Positive} + \text{False Negative}}
$$

**F1-스코어** : 정밀도와 재현율은 트레이드오프 관계. 이런 문제를 해결하려고 정밀도와 재현율의 조화 평균을 이용한 것이 F1-스코어.

$$
\mathrm{F1\text{-}스코어}= \frac{2 \times  \mathrm{Precision} \times \mathrm{Recall}}       {\mathrm{Precision} + \mathrm{Recall}}
$$

---

# 3장. 머신 러닝 핵심 알고리즘

## 3.1 지도 학습

정답을 컴퓨터에 미리 알려주고 데이터를 학습시키는 방법. 

- 분류 : 주어진 데이터를 정해진 범주에 따라 분류.
- 회귀 : 데이터들의 특성을 기준으로 연속된 값을 그래프로 표현하여 패턴이나 트렌드 예측.

![alt text](../img/멘멘/1주차/16.png)

### 3.1.1 K-최근접 이웃
새로운 입력을 받았을 때 기존 클러스터에서 모든 데이터와 인스턴스 기반 거리를 측정한 후 가장 많은 속성을 가진 클러스터에 할당하는 분류 알고리즘. 과거의 데이터를 사용하여 미리 분류 모형을 만드는 것이 아니라, 과거 데이터를 저장해 두고 필요할 때마다 비교를 수행하는 방식. K 값의 선택에 따라 분류 결과가 달라짐.

![alt text](../img/멘멘/1주차/17.png)
>**새로운 입력 1** : 주변 범주 세 개가 주황색이므로 주황색으로 분류.\
**새로운 입력 2** : 주변 범주 두 개가 주황색, 한 개가 녹색이므로 주황색으로 분류.\
**새로운 입력 3** : 주변 범주 두개가 녹색, 한 개가 주황색이므로 녹색으로 분류.

### 3.1.2 서포트 벡터 머신(SVM)

분류를 위한 기준선을 정의하는 모델. 분류되지 않은 새로운 데이터가 나타나면 결정 경계(기준선)를 기준으로 경계의 어느 쪽에 속하는지 분류하는 모델.

![alt text](../img/멘멘/1주차/18.png)

![alt text](../img/멘멘/1주차/19.png)
**마진** : 결정 경계와 서포트 벡터 사이의 거리를 의미함. 서포트 벡터는 결정 경계와 가까이 있는 데이터들을 의미함. → 최적의 결정 경계 : 마진 최대.

>마진을 최대화하기 위해선 이상치를 잘 다루는 것이 중요. 이상치를 허용하지 않는 것을 하드 마진이라고 하며, 어느 정도의 이상치들이 마진 안에 포함되는 것을 허용하면 소프트 마진.

### 3.1.3 결정 트리

데이터를 분류하거나 결과값을 예측하는 분석 방법.결정트리는 데이터를 1차로 분류 후, 각 영역의 순도는 증가하고 불순도와 불확실성은 감소하는 방향으로 학습 진행. ← 정보 획득.

### 3.1.4 로지스틱 회귀와 선형 회귀

- **로지스틱 회귀** : 분석하고자 하는 대상들이 두 집단 혹은 그 이상의 집단으로 나누어진 경우, 개별 관측치들이 어느 집단으로 분류될 수 있는지 분석하고 이를 예측하는 모형을 개발하는 데 사용되는 통계 기법.
1. 각 집단에 속하는 확률의 추정치 예측
2. 분류 기준 값을 설정한 후 특정 범주로 분류
- **선형 회귀** : 종속 변수와 독립 변수 사이의 관계를 설정하는 데 사용됨. 독립 변수가 변경되었을 때 종속 변수를 추정하는 데 유용. (x가 한 단위 올라갔을 때의 y)
![alt text](../img/멘멘/1주차/20.png)
